{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# IMPORTS AND SETUP\n",
    "# -------------------------\n",
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "#import range tqdm\n",
    "from tqdm import tqdm\n",
    "from tqdm import trange\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.data import Data\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATv2Conv, global_mean_pool\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class CustomGNN(nn.Module):\n",
    "    def __init__(self, num_node_features, num_edge_features, num_classes):\n",
    "        super(CustomGNN, self).__init__()\n",
    "        self.conv1 = GATv2Conv(num_node_features, 16, edge_dim=num_edge_features)\n",
    "        self.conv2 = GATv2Conv(16, 32, edge_dim=num_edge_features)\n",
    "        self.fc1 = nn.Linear(32, 16)\n",
    "        self.fc2 = nn.Linear(16, num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_attr, batch = data.x, data.edge_index, data.edge_attr, data.batch\n",
    "\n",
    "        x = F.relu(self.conv1(x, edge_index, edge_attr))\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "\n",
    "        x = F.relu(self.conv2(x, edge_index, edge_attr))\n",
    "        x = global_mean_pool(x, batch)  # Only if it's a graph classification task\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# GRAPH PROCESSING\n",
    "# -------------------------\n",
    "\n",
    "\n",
    "def graph_to_data(graph):\n",
    "    # Get a mapping from old node indices to new ones\n",
    "    node_mapping = {node: i for i, node in enumerate(graph.nodes())}\n",
    "\n",
    "    # Use the node mapping to convert node indices\n",
    "    edge_index = torch.tensor([(node_mapping[u], node_mapping[v]) for u, v in graph.edges()], dtype=torch.long).t().contiguous()\n",
    "\n",
    "\n",
    "    x = torch.tensor([[\n",
    "        attributes['struct_size'],\n",
    "        attributes['valid_pointer_count'],\n",
    "        attributes['invalid_pointer_count'],\n",
    "        attributes['first_pointer_offset'],\n",
    "        attributes['last_pointer_offset'],\n",
    "        attributes['first_valid_pointer_offset'],\n",
    "        attributes['last_valid_pointer_offset'],\n",
    "    ] for _, attributes in graph.nodes(data=True)], dtype=torch.float)\n",
    "\n",
    "    edge_attr = torch.tensor([data['offset'] for u, v, data in graph.edges(data=True)], dtype=torch.float).unsqueeze(1)\n",
    "    \n",
    "    # Convert x to a numpy array for normalization\n",
    "    x_np = x.numpy()\n",
    "\n",
    "    # Standardize features (subtract mean, divide by standard deviation)\n",
    "    x_np = (x_np - np.mean(x_np, axis=0)) / np.std(x_np, axis=0)\n",
    "\n",
    "    # Convert back to tensor\n",
    "    x = torch.tensor(x_np, dtype=torch.float)\n",
    "\n",
    "    edge_attr_np = edge_attr.numpy()\n",
    "    edge_attr_np = (edge_attr_np - np.mean(edge_attr_np, axis=0)) / np.std(edge_attr_np, axis=0)\n",
    "    edge_attr = torch.tensor(edge_attr_np, dtype=torch.float)\n",
    "\n",
    "    # if there are 2 keys then y = 0, if there are 4 keys then y = 1, if there are 6 keys then y = 2\n",
    "    key_count = len([node for node in graph.nodes() if graph.nodes[node]['cat'] == 1])\n",
    "\n",
    "    if key_count == 2:\n",
    "        y = torch.tensor(0, dtype=torch.long)  # Class index for 2 keys\n",
    "    elif key_count == 4:\n",
    "        y = torch.tensor(1, dtype=torch.long)  # Class index for 4 keys\n",
    "    elif key_count == 6:\n",
    "        y = torch.tensor(2, dtype=torch.long)  # Class index for 6 keys\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid number of keys: {key_count}\")\n",
    "    \n",
    "\n",
    "    return Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y)\n",
    "\n",
    "def remove_all_isolated_nodes(graph):\n",
    "    graph.remove_nodes_from(list(nx.isolates(graph)))\n",
    "    return graph\n",
    "\n",
    "def convert_types(G):\n",
    "    # Convert the string attributes to their corresponding types\n",
    "    for node, data in G.nodes(data=True):\n",
    "        # The label remains a string, so no conversion is needed for 'label'\n",
    "        # Convert struct_size, valid_pointer_count, invalid_pointer_count,\n",
    "        # first_pointer_offset, last_pointer_offset, first_valid_pointer_offset,\n",
    "        # last_valid_pointer_offset, and address to int\n",
    "        data['struct_size'] = int(data['struct_size'])\n",
    "        data['valid_pointer_count'] = int(data['valid_pointer_count'])\n",
    "        data['invalid_pointer_count'] = int(data['invalid_pointer_count'])\n",
    "        data['first_pointer_offset'] = int(data['first_pointer_offset'])\n",
    "        data['last_pointer_offset'] = int(data['last_pointer_offset'])\n",
    "        data['first_valid_pointer_offset'] = int(data['first_valid_pointer_offset'])\n",
    "        data['last_valid_pointer_offset'] = int(data['last_valid_pointer_offset'])\n",
    "        data['address'] = int(data['address'])\n",
    "\n",
    "        # Convert cat to an integer and ensure it's within the range of a byte (0-255)\n",
    "        data['cat'] = int(data['cat'])\n",
    "        if not (0 <= data['cat'] <= 255):\n",
    "            raise ValueError(f\"Value of 'cat' out of range for u8: {data['cat']}\")\n",
    "\n",
    "    # Convert edges to their corresponding types\n",
    "    for u, v, data in G.edges(data=True):\n",
    "        # Convert offset to int\n",
    "        data['offset'] = int(data['offset'])\n",
    "    return G\n",
    "\n",
    "\n",
    "\n",
    "def load_graphs(root_folder, max_per_subfolder=10, shuffle=False):\n",
    "    all_graphs = []\n",
    "\n",
    "    for subdir, dirs, files in os.walk(root_folder):\n",
    "        print(f\"Processing {subdir}...\")\n",
    "        graph_count = 0\n",
    "        for file in files:\n",
    "            if file.endswith('.graphml') and (max_per_subfolder == -1 or graph_count < max_per_subfolder ):\n",
    "                file_path = os.path.join(subdir, file)\n",
    "                try:\n",
    "                    graph = nx.read_graphml(file_path)\n",
    "                    all_graphs.append(graph)\n",
    "                    graph_count += 1\n",
    "                except Exception as e:\n",
    "                    print(f\"Error loading {file_path}: {e}\")\n",
    "\n",
    "    if shuffle:\n",
    "        random.shuffle(all_graphs)\n",
    "\n",
    "    return all_graphs\n",
    "\n",
    "\n",
    "def train(dataset):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = CustomGNN(num_node_features=7, num_classes=3, num_edge_features=1).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    # DataLoader\n",
    "    loader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "    print(f\"loader: {loader}\")\n",
    "    # Training Loop\n",
    "    for epoch in range(1000):\n",
    "        \n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for data in loader:\n",
    "            data = data.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            out = model(data)\n",
    "            loss = criterion(out, data.y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f'Epoch {epoch}, Loss: {total_loss / len(loader)}')\n",
    "    \n",
    "    return model\n",
    "\n",
    "def test(dataset, model):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.eval()\n",
    "    loader = DataLoader(dataset, batch_size=20, shuffle=False)\n",
    "    correct = 0\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        out = model(data)\n",
    "        pred = out.argmax(dim=1)\n",
    "        correct += int((pred == data.y).sum())\n",
    "    return correct / len(dataset)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /home/cyril/ssh-rlkex/Generated_Graphs/output...\n",
      "Processing /home/cyril/ssh-rlkex/Generated_Graphs/output/port-forwarding...\n",
      "Processing /home/cyril/ssh-rlkex/Generated_Graphs/output/port-forwarding/V_7_8_P1...\n",
      "Processing /home/cyril/ssh-rlkex/Generated_Graphs/output/port-forwarding/V_7_8_P1/64...\n",
      "Processing /home/cyril/ssh-rlkex/Generated_Graphs/output/port-forwarding/V_7_8_P1/16...\n",
      "Processing /home/cyril/ssh-rlkex/Generated_Graphs/output/port-forwarding/V_7_8_P1/32...\n",
      "Processing /home/cyril/ssh-rlkex/Generated_Graphs/output/port-forwarding/V_7_8_P1/24...\n",
      "Processing /home/cyril/ssh-rlkex/Generated_Graphs/output/port-forwarding/V_8_0_P1...\n",
      "Processing /home/cyril/ssh-rlkex/Generated_Graphs/output/port-forwarding/V_8_0_P1/64...\n",
      "Processing /home/cyril/ssh-rlkex/Generated_Graphs/output/port-forwarding/V_8_0_P1/16...\n",
      "Processing /home/cyril/ssh-rlkex/Generated_Graphs/output/port-forwarding/V_8_0_P1/32...\n",
      "Processing /home/cyril/ssh-rlkex/Generated_Graphs/output/port-forwarding/V_8_0_P1/24...\n",
      "Processing /home/cyril/ssh-rlkex/Generated_Graphs/output/scp...\n",
      "Processing /home/cyril/ssh-rlkex/Generated_Graphs/output/scp/V_7_8_P1...\n",
      "Processing /home/cyril/ssh-rlkex/Generated_Graphs/output/scp/V_7_8_P1/64...\n",
      "Processing /home/cyril/ssh-rlkex/Generated_Graphs/output/scp/V_7_8_P1/16...\n",
      "Processing /home/cyril/ssh-rlkex/Generated_Graphs/output/scp/V_7_8_P1/32...\n",
      "Processing /home/cyril/ssh-rlkex/Generated_Graphs/output/scp/V_7_8_P1/24...\n",
      "Processing /home/cyril/ssh-rlkex/Generated_Graphs/output/scp/V_8_0_P1...\n",
      "Processing /home/cyril/ssh-rlkex/Generated_Graphs/output/scp/V_8_0_P1/64...\n",
      "Processing /home/cyril/ssh-rlkex/Generated_Graphs/output/scp/V_8_0_P1/16...\n",
      "Processing /home/cyril/ssh-rlkex/Generated_Graphs/output/scp/V_8_0_P1/32...\n",
      "Processing /home/cyril/ssh-rlkex/Generated_Graphs/output/scp/V_8_0_P1/24...\n",
      "Processing /home/cyril/ssh-rlkex/Generated_Graphs/output/client...\n",
      "Processing /home/cyril/ssh-rlkex/Generated_Graphs/output/client/V_7_8_P1...\n",
      "Processing /home/cyril/ssh-rlkex/Generated_Graphs/output/client/V_7_8_P1/16...\n",
      "Processing /home/cyril/ssh-rlkex/Generated_Graphs/output/client/V_7_8_P1/32...\n",
      "Processing /home/cyril/ssh-rlkex/Generated_Graphs/output/client/V_7_8_P1/24...\n",
      "Processing /home/cyril/ssh-rlkex/Generated_Graphs/output/client/V_8_0_P1...\n",
      "Processing /home/cyril/ssh-rlkex/Generated_Graphs/output/client/V_8_0_P1/64...\n",
      "Processing /home/cyril/ssh-rlkex/Generated_Graphs/output/client/V_8_0_P1/16...\n",
      "Processing /home/cyril/ssh-rlkex/Generated_Graphs/output/client/V_8_0_P1/32...\n",
      "Processing /home/cyril/ssh-rlkex/Generated_Graphs/output/client/V_8_0_P1/24...\n",
      "Processing /home/cyril/ssh-rlkex/Generated_Graphs/output/basic...\n",
      "Processing /home/cyril/ssh-rlkex/Generated_Graphs/output/basic/V_7_2_P1...\n",
      "Processing /home/cyril/ssh-rlkex/Generated_Graphs/output/basic/V_7_2_P1/64...\n",
      "Processing /home/cyril/ssh-rlkex/Generated_Graphs/output/basic/V_7_2_P1/16...\n",
      "Processing /home/cyril/ssh-rlkex/Generated_Graphs/output/basic/V_7_2_P1/32...\n",
      "Processing /home/cyril/ssh-rlkex/Generated_Graphs/output/basic/V_7_2_P1/24...\n",
      "Processing /home/cyril/ssh-rlkex/Generated_Graphs/output/basic/V_6_9_P1...\n",
      "Processing /home/cyril/ssh-rlkex/Generated_Graphs/output/basic/V_6_9_P1/64...\n",
      "Processing /home/cyril/ssh-rlkex/Generated_Graphs/output/basic/V_6_9_P1/16...\n",
      "Processing /home/cyril/ssh-rlkex/Generated_Graphs/output/basic/V_6_9_P1/32...\n",
      "Processing /home/cyril/ssh-rlkex/Generated_Graphs/output/basic/V_6_9_P1/24...\n",
      "Processing /home/cyril/ssh-rlkex/Generated_Graphs/output/basic/V_7_0_P1...\n",
      "Processing /home/cyril/ssh-rlkex/Generated_Graphs/output/basic/V_7_0_P1/64...\n",
      "Processing /home/cyril/ssh-rlkex/Generated_Graphs/output/basic/V_7_0_P1/16...\n",
      "Processing /home/cyril/ssh-rlkex/Generated_Graphs/output/basic/V_7_0_P1/32...\n",
      "Processing /home/cyril/ssh-rlkex/Generated_Graphs/output/basic/V_7_0_P1/24...\n",
      "Processing /home/cyril/ssh-rlkex/Generated_Graphs/output/basic/V_8_1_P1...\n",
      "Processing /home/cyril/ssh-rlkex/Generated_Graphs/output/basic/V_8_1_P1/64...\n",
      "Processing /home/cyril/ssh-rlkex/Generated_Graphs/output/basic/V_8_1_P1/16...\n",
      "Processing /home/cyril/ssh-rlkex/Generated_Graphs/output/basic/V_8_1_P1/32...\n",
      "Processing /home/cyril/ssh-rlkex/Generated_Graphs/output/basic/V_8_1_P1/24...\n",
      "Processing /home/cyril/ssh-rlkex/Generated_Graphs/output/basic/V_6_8_P1...\n",
      "Processing /home/cyril/ssh-rlkex/Generated_Graphs/output/basic/V_6_8_P1/64...\n",
      "Processing /home/cyril/ssh-rlkex/Generated_Graphs/output/basic/V_6_8_P1/16...\n",
      "Processing /home/cyril/ssh-rlkex/Generated_Graphs/output/basic/V_6_8_P1/32...\n",
      "Processing /home/cyril/ssh-rlkex/Generated_Graphs/output/basic/V_6_8_P1/24...\n",
      "Processing /home/cyril/ssh-rlkex/Generated_Graphs/output/basic/V_7_9_P1...\n",
      "Processing /home/cyril/ssh-rlkex/Generated_Graphs/output/basic/V_7_9_P1/64...\n",
      "Processing /home/cyril/ssh-rlkex/Generated_Graphs/output/basic/V_7_9_P1/16...\n",
      "Processing /home/cyril/ssh-rlkex/Generated_Graphs/output/basic/V_7_9_P1/32...\n",
      "Processing /home/cyril/ssh-rlkex/Generated_Graphs/output/basic/V_7_9_P1/24...\n",
      "Processing /home/cyril/ssh-rlkex/Generated_Graphs/output/basic/V_7_8_P1...\n",
      "Processing /home/cyril/ssh-rlkex/Generated_Graphs/output/basic/V_7_8_P1/64...\n",
      "Processing /home/cyril/ssh-rlkex/Generated_Graphs/output/basic/V_7_8_P1/16...\n",
      "Processing /home/cyril/ssh-rlkex/Generated_Graphs/output/basic/V_7_8_P1/32...\n",
      "Processing /home/cyril/ssh-rlkex/Generated_Graphs/output/basic/V_7_8_P1/24...\n",
      "Processing /home/cyril/ssh-rlkex/Generated_Graphs/output/basic/V_7_1_P1...\n",
      "Processing /home/cyril/ssh-rlkex/Generated_Graphs/output/basic/V_7_1_P1/64...\n",
      "Processing /home/cyril/ssh-rlkex/Generated_Graphs/output/basic/V_7_1_P1/16...\n",
      "Processing /home/cyril/ssh-rlkex/Generated_Graphs/output/basic/V_7_1_P1/32...\n",
      "Processing /home/cyril/ssh-rlkex/Generated_Graphs/output/basic/V_7_1_P1/24...\n",
      "Processing /home/cyril/ssh-rlkex/Generated_Graphs/output/basic/V_8_7_P1...\n",
      "Processing /home/cyril/ssh-rlkex/Generated_Graphs/output/basic/V_8_7_P1/64...\n",
      "Processing /home/cyril/ssh-rlkex/Generated_Graphs/output/basic/V_8_7_P1/16...\n",
      "Processing /home/cyril/ssh-rlkex/Generated_Graphs/output/basic/V_8_7_P1/32...\n",
      "Processing /home/cyril/ssh-rlkex/Generated_Graphs/output/basic/V_8_7_P1/24...\n",
      "Processing /home/cyril/ssh-rlkex/Generated_Graphs/output/basic/V_8_0_P1...\n",
      "Processing /home/cyril/ssh-rlkex/Generated_Graphs/output/basic/V_8_0_P1/64...\n",
      "Processing /home/cyril/ssh-rlkex/Generated_Graphs/output/basic/V_8_0_P1/16...\n",
      "Processing /home/cyril/ssh-rlkex/Generated_Graphs/output/basic/V_8_0_P1/32...\n",
      "Processing /home/cyril/ssh-rlkex/Generated_Graphs/output/basic/V_8_0_P1/24...\n",
      "Processing /home/cyril/ssh-rlkex/Generated_Graphs/output/basic/V_8_8_P1...\n",
      "Processing /home/cyril/ssh-rlkex/Generated_Graphs/output/basic/V_8_8_P1/64...\n",
      "Processing /home/cyril/ssh-rlkex/Generated_Graphs/output/basic/V_8_8_P1/16...\n",
      "Processing /home/cyril/ssh-rlkex/Generated_Graphs/output/basic/V_8_8_P1/32...\n",
      "Processing /home/cyril/ssh-rlkex/Generated_Graphs/output/basic/V_8_8_P1/24...\n",
      "Loaded 670 graphs\n",
      "Removed isolated nodes from graphs\n",
      "Loaded 670 graphs\n"
     ]
    }
   ],
   "source": [
    "\n",
    "folder = '/home/cyril/ssh-rlkex/Generated_Graphs/output'\n",
    "graphs = load_graphs(folder)\n",
    "print(f\"Loaded {len(graphs)} graphs\")\n",
    "graphs = [convert_types(graph) for graph in graphs]\n",
    "graphs = [remove_all_isolated_nodes(graph) for graph in graphs]\n",
    "print(f\"Removed isolated nodes from graphs\")\n",
    "print(f\"Loaded {len(graphs)} graphs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted graphs to data\n"
     ]
    }
   ],
   "source": [
    "dataset = [graph_to_data(graph) for graph in graphs]\n",
    "print(f\"Converted graphs to data\")\n",
    "\n",
    "#split the dataset into train and test and shuffle\n",
    "random.shuffle(dataset)\n",
    "train_factor = 0.75\n",
    "train_dataset = dataset[:int(len(dataset)*train_factor)]\n",
    "test_dataset = dataset[int(len(dataset)*train_factor):]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 670 graphs\n",
      "loader: <torch_geometric.deprecation.DataLoader object at 0x7f12c817b430>\n",
      "Epoch 0, Loss: 1.0937160849571228\n",
      "Epoch 1, Loss: 1.0611453615128994\n",
      "Epoch 2, Loss: 1.066734004765749\n",
      "Epoch 3, Loss: 1.0591284334659576\n",
      "Epoch 4, Loss: 1.0581242069602013\n",
      "Epoch 5, Loss: 1.0503958389163017\n",
      "Epoch 6, Loss: 1.0264973491430283\n",
      "Epoch 7, Loss: 0.9937889464199543\n",
      "Epoch 8, Loss: 0.9446803852915764\n",
      "Epoch 9, Loss: 0.9085889086127281\n",
      "Epoch 10, Loss: 0.8577879555523396\n",
      "Epoch 11, Loss: 0.854322075843811\n",
      "Epoch 12, Loss: 0.812379963696003\n",
      "Epoch 13, Loss: 0.7697853036224842\n",
      "Epoch 14, Loss: 0.6817994341254234\n",
      "Epoch 15, Loss: 0.6911997906863689\n",
      "Epoch 16, Loss: 0.6573486085981131\n",
      "Epoch 17, Loss: 0.5941939689218998\n",
      "Epoch 18, Loss: 0.5819779094308615\n",
      "Epoch 19, Loss: 0.5373622830957174\n",
      "Epoch 20, Loss: 0.5365627594292164\n",
      "Epoch 21, Loss: 0.49963308311998844\n",
      "Epoch 22, Loss: 0.4870981313288212\n",
      "Epoch 23, Loss: 0.46803306229412556\n",
      "Epoch 24, Loss: 0.5055736117064953\n",
      "Epoch 25, Loss: 0.4719718210399151\n",
      "Epoch 26, Loss: 0.4933582544326782\n",
      "Epoch 27, Loss: 0.4845673367381096\n",
      "Epoch 28, Loss: 0.5093949213624\n",
      "Epoch 29, Loss: 0.40457601100206375\n",
      "Epoch 30, Loss: 0.43135698325932026\n",
      "Epoch 31, Loss: 0.4169013611972332\n",
      "Epoch 32, Loss: 0.3877584859728813\n",
      "Epoch 33, Loss: 0.3856058483943343\n",
      "Epoch 34, Loss: 0.45428633876144886\n",
      "Epoch 35, Loss: 0.38468631356954575\n",
      "Epoch 36, Loss: 0.3778096055611968\n",
      "Epoch 37, Loss: 0.42661324702203274\n",
      "Epoch 38, Loss: 0.4159088162705302\n",
      "Epoch 39, Loss: 0.3334722826257348\n",
      "Epoch 40, Loss: 0.35780595894902945\n",
      "Epoch 41, Loss: 0.32192562613636255\n",
      "Epoch 42, Loss: 0.4057124564424157\n",
      "Epoch 43, Loss: 0.38659382052719593\n",
      "Epoch 44, Loss: 0.3369120052084327\n",
      "Epoch 45, Loss: 0.3414562465623021\n",
      "Epoch 46, Loss: 0.3194855097681284\n",
      "Epoch 47, Loss: 0.31780034862458706\n",
      "Epoch 48, Loss: 0.3200121056288481\n",
      "Epoch 49, Loss: 0.3702320568263531\n",
      "Epoch 50, Loss: 0.3745588129386306\n",
      "Epoch 51, Loss: 0.3659951025620103\n",
      "Epoch 52, Loss: 0.3230439694598317\n",
      "Epoch 53, Loss: 0.3600219087675214\n",
      "Epoch 54, Loss: 0.34097986156120896\n",
      "Epoch 55, Loss: 0.3409220399335027\n",
      "Epoch 56, Loss: 0.3169950577430427\n",
      "Epoch 57, Loss: 0.29984927363693714\n",
      "Epoch 58, Loss: 0.3092299522832036\n",
      "Epoch 59, Loss: 0.27283915504813194\n",
      "Epoch 60, Loss: 0.30871916748583317\n",
      "Epoch 61, Loss: 0.3964880667626858\n",
      "Epoch 62, Loss: 0.38299096655100584\n",
      "Epoch 63, Loss: 0.3192600328475237\n",
      "Epoch 64, Loss: 0.3184389527887106\n",
      "Epoch 65, Loss: 0.33997021429240704\n",
      "Epoch 66, Loss: 0.2928012115880847\n",
      "Epoch 67, Loss: 0.3164874534122646\n",
      "Epoch 68, Loss: 0.34650748036801815\n",
      "Epoch 69, Loss: 0.29640079755336046\n",
      "Epoch 70, Loss: 0.3230664739385247\n",
      "Epoch 71, Loss: 0.35278597846627235\n",
      "Epoch 72, Loss: 0.32452474627643824\n",
      "Epoch 73, Loss: 0.26703573390841484\n",
      "Epoch 74, Loss: 0.2943466193974018\n",
      "Epoch 75, Loss: 0.37107438361272216\n",
      "Epoch 76, Loss: 0.3242578264325857\n",
      "Epoch 77, Loss: 0.2973003890365362\n",
      "Epoch 78, Loss: 0.3122951677069068\n",
      "Epoch 79, Loss: 0.3432435682043433\n",
      "Epoch 80, Loss: 0.3057249905541539\n",
      "Epoch 81, Loss: 0.340098868124187\n",
      "Epoch 82, Loss: 0.22873526765033603\n",
      "Epoch 83, Loss: 0.2842877544462681\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"Loaded {len(dataset)} graphs\")\n",
    "model = train(train_dataset)\n",
    "print(f\"Trained model\")\n",
    "\n",
    "\n",
    "accuracy = test(test_dataset, model)\n",
    "print(f\"Test accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.bias tensor(0., device='cuda:0')\n",
      "conv1.lin.weight tensor(0., device='cuda:0')\n",
      "conv2.bias tensor(0., device='cuda:0')\n",
      "conv2.lin.weight tensor(0., device='cuda:0')\n",
      "fc.weight tensor(0., device='cuda:0')\n",
      "fc.bias tensor(0., device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.grad.norm())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test GCNCOnv didn't work well, output was all 0, I don't really know why\n",
    "#Then I tried GATConv, it worked well, but the accuracy is not very high, I think it's because the dataset is too small\n",
    "#TRying gatv2conv with edge attributes, it worked well\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PhD-Track",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
